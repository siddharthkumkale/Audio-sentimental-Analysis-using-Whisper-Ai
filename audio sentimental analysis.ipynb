{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dcab3bf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"text\": \"Hello? Hello? Yes sir. 1st November 1988. One minute. 1st November 1988. Ok. And the name of the business is Siddhi Vinayak Medical and General Store. Correct. What kind of business is it? It is a medical store. Medical store. What kind of medicines? Allopathic or Ayurvedic? Allopathic and Ayurvedic. Ok. One minute. All types of medicines? Allopathic, Homeopathic and Ayurvedic. And you do this in retail, right? It is a medical store, right? Yes. Is it sold in wholesale? No, no. Not in wholesale. Only retail, right? Medical store. Yes.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import openai\n",
    "\n",
    "\n",
    "openai.api_key = \"sk-proj-ir2UbanfdRQ5qDRehclXT3BlbkFJ2JNlDJ8XI8W3iNGybu54\"\n",
    "\n",
    "\n",
    "audio_path = 'audio1trim.mp3'\n",
    "audio_file = open(audio_path, \"rb\")\n",
    "response = openai.Audio.translate(\"whisper-1\", audio_file)\n",
    "\n",
    "\n",
    "\n",
    "print(response)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eaad223c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translation response: Hello? Hello? Yes sir. 1st November 1988. One minute. 1st November 1988. Ok. And the name of the business is Siddhi Vinayak Medical and General Store. Correct. What kind of business is it? It is a medical store. Medical store. What kind of medicines? Allopathic or Ayurvedic? Allopathic and Ayurvedic. Ok. One minute. All types of medicines? Allopathic, Homeopathic and Ayurvedic. And you do this in retail, right? It is a medical store, right? Yes. Is it sold in wholesale? No, no. Not in wholesale. Only retail, right? Medical store. Yes.\n",
      "Speaker B: Hello?\n",
      "Speaker A: Hello?\n",
      "Speaker A: Yes sir.\n",
      "Speaker B: 1st November 1988.\n",
      "Speaker A: One\n",
      "Speaker A: minute.\n",
      "Speaker A: 1st November 1988.\n",
      "Speaker B: Ok.\n",
      "Speaker A: And the\n",
      "Speaker B: name\n",
      "Speaker A: of\n",
      "Speaker A: the business is Siddhi Vinayak\n",
      "Speaker B: Medical\n",
      "Speaker A: and General Store. Correct.\n",
      "Speaker B: What kind of\n",
      "Speaker A: business is\n",
      "Speaker A: it? It is a medical store. Medical store. What kind\n",
      "Speaker B: of\n",
      "Speaker B: medicines? Allopathic or\n",
      "Speaker A: Ayurvedic?\n",
      "Speaker B: Allopathic and\n",
      "Speaker A: Ayurvedic. Ok. One minute. All\n",
      "Speaker B: types of\n",
      "Speaker B: medicines? Allopathic, Homeopathic and Ayurvedic. And you do\n",
      "Speaker A: this\n",
      "Speaker A: in\n",
      "Speaker A: retail, right? It is\n",
      "Speaker B: a medical store, right?\n",
      "Speaker A: Yes. Is it sold in\n",
      "Speaker A: wholesale?\n",
      "Speaker B: No,\n",
      "Speaker A: no. Not in wholesale. Only\n",
      "Speaker B: retail, right?\n",
      "Speaker B: Medical\n",
      "Speaker B: store.\n",
      "Speaker A: Yes.\n",
      "Speaker B: \n",
      "Speaker A: \n",
      "Speaker A: \n",
      "Speaker B: \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "from pyannote.audio import Pipeline\n",
    "import math\n",
    "\n",
    "# OpenAI API key\n",
    "openai.api_key = \"sk-proj-ir2UbanfdRQ5qDRehclXT3BlbkFJ2JNlDJ8XI8W3iNGybu54\"\n",
    "\n",
    "# Path to the audio file\n",
    "audio_path = 'audio1trim.mp3'\n",
    "\n",
    "# Translate the audio using OpenAI Whisper API\n",
    "with open(audio_path, \"rb\") as audio_file:\n",
    "    response = openai.Audio.translate(\"whisper-1\", audio_file)\n",
    "\n",
    "transcription_text = response['text']\n",
    "print(\"Translation response:\", transcription_text)\n",
    "\n",
    "# Perform speaker diarization using PyAnnote\n",
    "pipeline = Pipeline.from_pretrained(\n",
    "    \"pyannote/speaker-diarization-3.1\",\n",
    "    use_auth_token=\"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\"\n",
    ")\n",
    "\n",
    "# Run the pipeline on the audio file\n",
    "diarization = pipeline(audio_path, num_speakers=2)\n",
    "\n",
    "# Split the transcription text into words\n",
    "words = transcription_text.split()\n",
    "\n",
    "\n",
    "# Calculate total duration of the audio\n",
    "total_duration = diarization.get_timeline().extent().duration\n",
    "\n",
    "# Estimate average duration per word\n",
    "average_word_duration = total_duration / len(words)\n",
    "\n",
    "# Assign words to speaker segments and print the formatted conversation\n",
    "current_word_idx = 0\n",
    "formatted_conversation = \"\"\n",
    "\n",
    "for turn, _, speaker in diarization.itertracks(yield_label=True):\n",
    "    speaker_label = \"Speaker A\" if speaker == \"SPEAKER_00\" else \"Speaker B\"\n",
    "    \n",
    "    # Collect words spoken in this segment\n",
    "    segment_text = []\n",
    "    segment_duration = turn.end - turn.start\n",
    "    words_in_segment = math.ceil(segment_duration / average_word_duration)\n",
    "    \n",
    "    for _ in range(words_in_segment):\n",
    "        if current_word_idx < len(words):\n",
    "            segment_text.append(words[current_word_idx])\n",
    "            current_word_idx += 1\n",
    "    \n",
    "    # Append to the formatted conversation\n",
    "    formatted_conversation += f\"{speaker_label}: {' '.join(segment_text)}\\n\"\n",
    "\n",
    "# Print the formatted conversation\n",
    "print(formatted_conversation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d1d7589c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translation response: Hello? Hello? Yes sir. 1st November 1988. One minute. 1st November 1988. Ok. And the name of the business is Siddhi Vinayak Medical and General Store. Correct. What kind of business is it? It is a medical store. Medical store. What kind of medicines? Allopathic or Ayurvedic? Allopathic and Ayurvedic. Ok. One minute. All types of medicines? Allopathic, Homeopathic and Ayurvedic. And you do this in retail, right? It is a medical store, right? Yes. Is it sold in wholesale? No, no. Not in wholesale. Only retail, right? Medical store. Yes.\n",
      "      Speaker                                               Text\n",
      "0   Speaker B                                             Hello?\n",
      "1   Speaker A                                             Hello?\n",
      "2   Speaker A                                           Yes sir.\n",
      "3   Speaker B                                 1st November 1988.\n",
      "4   Speaker A                                                One\n",
      "5   Speaker A                                            minute.\n",
      "6   Speaker A                                 1st November 1988.\n",
      "7   Speaker B                                                Ok.\n",
      "8   Speaker A                                            And the\n",
      "9   Speaker B                                               name\n",
      "10  Speaker A                                                 of\n",
      "11  Speaker A                     the business is Siddhi Vinayak\n",
      "12  Speaker B                                            Medical\n",
      "13  Speaker A                        and General Store. Correct.\n",
      "14  Speaker B                                       What kind of\n",
      "15  Speaker A                                        business is\n",
      "16  Speaker A  it? It is a medical store. Medical store. What...\n",
      "17  Speaker B                                                 of\n",
      "18  Speaker B                           medicines? Allopathic or\n",
      "19  Speaker A                                         Ayurvedic?\n",
      "20  Speaker B                                     Allopathic and\n",
      "21  Speaker A                     Ayurvedic. Ok. One minute. All\n",
      "22  Speaker B                                           types of\n",
      "23  Speaker B  medicines? Allopathic, Homeopathic and Ayurved...\n",
      "24  Speaker A                                               this\n",
      "25  Speaker A                                                 in\n",
      "26  Speaker A                               retail, right? It is\n",
      "27  Speaker B                            a medical store, right?\n",
      "28  Speaker A                                 Yes. Is it sold in\n",
      "29  Speaker A                                         wholesale?\n",
      "30  Speaker B                                                No,\n",
      "31  Speaker B                                                no.\n",
      "32  Speaker A                     Not in wholesale. Only retail,\n",
      "33  Speaker B                                             right?\n",
      "34  Speaker B                                            Medical\n",
      "35  Speaker B                                             store.\n",
      "36  Speaker B                                               Yes.\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "from pyannote.audio import Pipeline\n",
    "import math\n",
    "import pandas as pd\n",
    "\n",
    "# OpenAI API key\n",
    "openai.api_key = \"sk-proj-ir2UbanfdRQ5qDRehclXT3BlbkFJ2JNlDJ8XI8W3iNGybu54\"\n",
    "\n",
    "# Path to the audio file\n",
    "audio_path = 'audio1trim.mp3'\n",
    "\n",
    "# Translate the audio using OpenAI Whisper API\n",
    "with open(audio_path, \"rb\") as audio_file:\n",
    "    response = openai.Audio.translate(\"whisper-1\", audio_file)\n",
    "\n",
    "transcription_text = response['text']\n",
    "print(\"Translation response:\", transcription_text)\n",
    "\n",
    "# Perform speaker diarization using PyAnnote\n",
    "pipeline = Pipeline.from_pretrained(\"pyannote/speaker-diarization-3.1\")\n",
    "\n",
    "# Run the pipeline on the audio file\n",
    "diarization = pipeline(audio_path, num_speakers=2)\n",
    "\n",
    "# Split the transcription text into words\n",
    "words = transcription_text.split()\n",
    "\n",
    "# Calculate total duration of the audio\n",
    "total_duration = diarization.get_timeline().extent().duration\n",
    "\n",
    "# Estimate average duration per word\n",
    "average_word_duration = total_duration / len(words)\n",
    "\n",
    "# Create a list to store speaker segments\n",
    "segments = []\n",
    "\n",
    "# Assign words to speaker segments\n",
    "current_word_idx = 0\n",
    "\n",
    "for turn, _, speaker in diarization.itertracks(yield_label=True):\n",
    "    speaker_label = \"Speaker A\" if speaker == \"SPEAKER_00\" else \"Speaker B\"\n",
    "    \n",
    "    # Collect words spoken in this segment\n",
    "    segment_text = []\n",
    "    segment_duration = turn.end - turn.start\n",
    "    words_in_segment = math.ceil(segment_duration / average_word_duration)\n",
    "    \n",
    "    for _ in range(words_in_segment):\n",
    "        if current_word_idx < len(words):\n",
    "            segment_text.append(words[current_word_idx])\n",
    "            current_word_idx += 1\n",
    "        else:\n",
    "            break  # If we've run out of words to assign, break out of the loop\n",
    "    \n",
    "    # Append speaker segment to the list if it contains text\n",
    "    if segment_text:\n",
    "        segments.append((speaker_label, ' '.join(segment_text)))\n",
    "\n",
    "# Create DataFrame from the list of speaker segments\n",
    "df = pd.DataFrame(segments, columns=['Speaker', 'Text'])\n",
    "\n",
    "# Print the DataFrame\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61354bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71e2f78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string\n",
    "from textblob import TextBlob\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a443b870",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Si004\n",
      "[nltk_data]     (293400)\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to C:\\Users\\Si004\n",
      "[nltk_data]     (293400)\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\Si004\n",
      "[nltk_data]     (293400)\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Initialize OpenAI API key\n",
    "openai.api_key = \"sk-proj-ir2UbanfdRQ5qDRehclXT3BlbkFJ2JNlDJ8XI8W3iNGybu54\"\n",
    "\n",
    "# Transcription part\n",
    "audio_path = 'audio1trim.mp3'\n",
    "audio_file = open(audio_path, \"rb\")\n",
    "response = openai.Audio.translate(\"whisper-1\", audio_file)\n",
    " \n",
    "# Ensure response contains the transcribed text\n",
    "transcribed_text = response.get('text', '')\n",
    "\n",
    "# Ensure necessary NLTK data files are downloaded\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Initialize stop words, lemmatizer, and punctuation list\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "punctuations = string.punctuation\n",
    "\n",
    "def clean_text(text):\n",
    "    # Tokenize the text\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Remove stop words and punctuations, and lemmatize the words\n",
    "    cleaned_tokens = [\n",
    "        lemmatizer.lemmatize(word.lower())\n",
    "        for word in tokens\n",
    "        if word.lower() not in stop_words and word not in punctuations\n",
    "    ]\n",
    "    \n",
    "    return ' '.join(cleaned_tokens)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3d6621f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment(polarity=0.239010989010989, subjectivity=0.3774725274725274)\n"
     ]
    }
   ],
   "source": [
    "# Clean the transcribed text\n",
    "cleaned_text = clean_text(transcribed_text)\n",
    "\n",
    "def analyze_sentiment(text):\n",
    "    blob = TextBlob(text)\n",
    "    return blob.sentiment\n",
    "\n",
    "# Analyze sentiment of the cleaned text\n",
    "sentiment = analyze_sentiment(cleaned_text)\n",
    "print(sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ef2821d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VADER Sentiment: {'neg': 0.0, 'neu': 0.713, 'pos': 0.287, 'compound': 0.9538}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to C:\\Users\\Si004\n",
      "[nltk_data]     (293400)\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "# Download VADER lexicon\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "# Initialize VADER sentiment analyzer\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Analyze sentiment\n",
    "vader_sentiment = sia.polarity_scores(cleaned_text)\n",
    "print(\"VADER Sentiment:\", vader_sentiment)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce93a766",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b201bc9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
